D:\GitHub\Spacy-Serbian-Transformer> python -m spacy init fill-config ./base_config12.cfg ./config12.cfg
✔ Auto-filled config with all values
✔ Saved config
config12.cfg
You can now add your data and train your pipeline:
python -m spacy train config12.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
PS D:\GitHub\Spacy-Serbian-Transformer> python -m spacy train config12.cfg --output ./model12 --gpu-id 0   
ℹ Saving to output directory: model12
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
Some weights of RobertaModel were not initialized from the model checkpoint at bertovic-base3 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'ner']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE
---  ------  -------------  --------  ------  ------  ------  ------
  0       0       44542.72   1219.67    0.00    0.00    0.00    0.00
  3     200     1433622.12  70100.68   79.56   91.38   70.45    0.80
  7     400       12906.67   3167.84   84.35   83.91   84.80    0.84
 11     600       17732.04   1758.67   83.74   89.42   78.73    0.84
  83.67   85.97    0.85
 37    2000          64.90    594.04   83.66   87.85   79.85    0.84
 41    2200          57.95    584.51   84.12   86.70   81.69    0.84
 45    2400         107.10    600.06   84.00   84.41   83.60    0.84
 49    2600         128.11    570.32   83.72   82.79   84.68    0.84
 52    2800          32.58    495.94   83.45   88.59   78.88    0.83
 56    3000          16.64    484.51   84.45   87.16   81.90    0.84
 60    3200          32.23    472.92   84.33   89.35   79.85    0.84
 64    3400          10.97    441.57   84.07   85.07   83.10    0.84
✔ Saved pipeline to output directory
model12\model-last

PS D:\GitHub\Spacy-Serbian-Transformer> python -m spacy benchmark accuracy ./model12/model-best ./Corpus/SrpELTeC-gold-test.spacy --output ./eval_results12.json --gpu-id 0  
ℹ Using GPU: 0

================================== Results ==================================

TOK     100.00
NER P   80.61
NER R   85.92
NER F   83.18
SPEED   10924


=============================== NER (per type) ===============================

            P       R       F
ROLE    76.13   79.73   77.89
PERS    84.08   93.24   88.42
LOC     77.41   75.82   76.60
ORG     50.00   28.57   36.36
DEMO    77.39   73.55   75.42
WORK     0.00    0.00    0.00
EVENT    0.00    0.00    0.00
