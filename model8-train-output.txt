(spacy) D:\GitHub\Spacy-Serbian-Transformer>python -m spacy train config8.cfg --output ./model8 --gpu-id 0
ℹ Saving to output directory: model8
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'morphologizer', 'trainable_lemmatizer',
'tagger', 'parser']
ℹ Frozen components: ['morphologizer', 'trainable_lemmatizer']
ℹ Set annotations on update for: ['morphologizer',
'trainable_lemmatizer', 'tagger']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TAGGER  LOSS PARSER  POS_ACC  MORPH_ACC  LEMMA_ACC  TAG_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE
---  ------  -------------  -----------  -----------  -------  ---------  ---------  -------  -------  -------  -------  ------
  0       0        1756.68       707.73      1339.40    91.70      20.32      86.01     0.02    10.51     2.00     0.04    0.37
  4     200      378937.30    358668.53    330213.93    91.70      20.32      86.01    46.83    85.80    79.21    70.34    0.68
  9     400       84531.12    203384.64     84991.88    91.70      20.32      86.01    87.65    91.41    87.65    88.44    0.80
 14     600       37352.59     38357.18     40542.20    91.70      20.32      86.01    93.32    92.42    88.95    93.01    0.82
 19     800       17694.56     13434.05     23906.64    91.70      20.32      86.01    94.95    92.70    89.34    93.23    0.82
 24    1000       10668.54      6305.87     18297.93    91.70      20.32      86.01    95.24    93.40    90.18    96.55    0.83
 29    1200        7931.20      3489.48     16212.50    91.70      20.32      86.01    95.49    93.28    89.93    96.83    0.83
 34    1400        6377.06      2296.12     15236.36    91.70      20.32      86.01    95.38    93.06    89.64    95.49    0.83
 39    1600        5428.85      1783.43     14881.10    91.70      20.32      86.01    95.54    93.14    89.84    95.61    0.83
 44    1800        4814.48      1399.15     14528.55    91.70      20.32      86.01    95.55    93.17    90.01    95.90    0.83
 49    2000        4353.86      1177.09     14351.91    91.70      20.32      86.01    95.42    93.33    90.15    96.92    0.83
 54    2200        4411.70      1099.70     14497.40    91.70      20.32      86.01    95.37    93.42    90.10    96.07    0.83
 58    2400        3704.45      1092.16     14163.49    91.70      20.32      86.01    95.51    93.31    90.15    95.72    0.83
 63    2600        3342.24      1073.07     13976.73    91.70      20.32      86.01    95.48    92.96    89.92    96.67    0.83
 68    2800        3442.38      1036.12     13908.32    91.70      20.32      86.01    95.34    93.29    90.22    95.81    0.83
 73    3000        3504.15       989.41     14152.02    91.70      20.32      86.01    95.33    93.19    89.90    96.54    0.83
 78    3200        2978.92      1038.45     13672.77    91.70      20.32      86.01    95.55    93.38    90.15    96.74    0.83
 83    3400        2837.41       967.97     13872.99    91.70      20.32      86.01    95.60    93.51    90.41    97.40    0.83
 88    3600        2424.92      1030.87     13833.23    91.70      20.32      86.01    95.41    93.50    90.38    96.84    0.83
 93    3800        2501.74      1010.48     13550.97    91.70      20.32      86.01    95.52    93.43    90.35    96.38    0.83
 98    4000        2466.66       989.34     13725.87    91.70      20.32      86.01    95.51    93.45    90.31    97.21    0.83
103    4200        2401.67       962.92     13526.20    91.70      20.32      86.01    95.43    93.40    90.24    96.57    0.83
108    4400        2567.78       952.21     13590.86    91.70      20.32      86.01    95.49    93.48    89.94    95.98    0.83
113    4600        2281.50       947.05     13684.89    91.70      20.32      86.01    95.44    93.44    90.07    96.93    0.83
118    4800        2102.66       939.21     13585.03    91.70      20.32      86.01    95.28    93.65    90.40    97.67    0.83
123    5000        2158.24       970.29     13414.37    91.70      20.32      86.01    95.47    93.64    90.37    96.17    0.83
✔ Saved pipeline to output directory
model8\model-last

(spacy) D:\GitHub\Spacy-Serbian-Transformer>python -m spacy benchmark accuracy ./model8/model-best ./Corpus/sr_set-ud-test.spacy --output ./eval_results8.json --gpu-id 0
ℹ Using GPU: 0

================================== Results ==================================

TOK      100.00
TAG      96.01
POS      91.70
MORPH    19.77
LEMMA    87.25
UAS      94.10
LAS      91.16
SENT P   95.87
SENT R   98.27
SENT F   97.06
SPEED    1608


============================== MORPH (per feat) ==============================

                  P      R      F
Case           0.00   0.00   0.00
Gender         0.00   0.00   0.00
Number         0.00   0.00   0.00
Tense          0.00   0.00   0.00
VerbForm       0.00   0.00   0.00
Voice          0.00   0.00   0.00
Animacy        0.00   0.00   0.00
Definite       0.00   0.00   0.00
Degree         0.00   0.00   0.00
Mood           0.00   0.00   0.00
Person         0.00   0.00   0.00
PronType       0.00   0.00   0.00
Polarity       0.00   0.00   0.00
Poss           0.00   0.00   0.00
Reflex         0.00   0.00   0.00
Number[psor]   0.00   0.00   0.00
NumType        0.00   0.00   0.00
Foreign        0.00   0.00   0.00
Gender[psor]   0.00   0.00   0.00


=============================== LAS (per type) ===============================

                  P        R       F
nsubj         94.50    93.95   94.22
cc            94.24    95.34   94.78
conj          85.61    85.42   85.52
root          95.12    97.50   96.30
obj           94.24    95.19   94.71
case          97.46    97.63   97.54
nmod          87.12    89.30   88.19
amod          95.99    97.38   96.68
aux           94.16    96.45   95.29
obl           87.82    85.73   86.76
mark          94.43    95.70   95.06
cop           85.16    79.52   82.24
ccomp         95.17    84.66   89.61
advcl         70.73    73.42   72.05
xcomp         82.00    89.78   85.71
acl           82.32    80.69   81.50
flat          88.60    84.87   86.70
advmod        85.94    84.59   85.26
discourse     57.45    50.94   54.00
appos         57.33    55.13   56.21
parataxis     78.72    82.22   80.43
det           96.20    94.65   95.42
nummod        94.34    76.92   84.75
csubj         73.91    70.83   72.34
fixed         86.21    84.75   85.47
expl         100.00    99.35   99.68
nummod:gov    80.28    87.69   83.82
orphan         0.00     0.00    0.00
det:numgov    78.57   100.00   88.00
dep            0.00     0.00    0.00

✔ Saved results to eval_results8.json